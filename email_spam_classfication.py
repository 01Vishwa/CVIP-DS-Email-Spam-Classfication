# -*- coding: utf-8 -*-
"""Email Spam Classfication.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pCTI_XfkF0YGwwUgZPh8zbBr7gHyCy2z
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_curve, roc_auc_score, precision_score

data=pd.read_csv("/content/Spam.csv")

data.head()

data.info()

data.describe().T

data.isnull().sum()

data.corr()

cor_mat= data.corr()
mask = np.array(cor_mat)
mask[np.tril_indices_from(mask)] = False
fig=plt.gcf()
fig.set_size_inches(50,50)
sns.heatmap(data=cor_mat,mask=mask,square=True,annot=True,cbar=True)

value_counts = data['spam'].value_counts()
data['spam'] = data['spam'].map({1: 'Spam', 0: 'Not Spam'})
value_counts = data['spam'].value_counts()

plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%')
plt.title('Distribution of Spam and Not Spam')
plt.show()

plt.scatter(data['capital_run_length_total'], data['capital_run_length_average'], marker = 'o', color = 'r')
plt.title('Total VS Average', fontsize = 15, pad = 12, color = 'b')
plt.xlabel('Count of Capital Run Length Total')
plt.ylabel('Capital Run Length Average')
plt.show()

plt.scatter(data['capital_run_length_total'], data['capital_run_length_longest'], marker = '+', color = 'b')
plt.title('Total ~ Longest', fontsize = 15, pad = 12, color = 'r')
plt.xlabel('Count of Capital Run Length Total')
plt.ylabel('Count of Capital Run Length Longest')
plt.show()

plt.scatter(data['capital_run_length_longest'], data['capital_run_length_average'], marker = '^', color = 'lightseagreen')
plt.title('Longest ~ Average', fontsize = 15, pad = 12, color = 'purple')
plt.xlabel('Count of Capital Run Length Longest')
plt.ylabel('Capital Run Length Average')
plt.show()

X = data.drop(["spam"], axis=1)
y = data["spam"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

gnb = GaussianNB()

gnb.fit(X_train, y_train)

print('Accuracy Score :', gnb.score(X_test, y_test))

rf = RandomForestClassifier()

rf.fit(X_train, y_train)

print('Accuracy Score:', rf.score(X_test, y_test))

lg= LogisticRegression(max_iter=1000)

lg.fit(X_train, y_train)

print('Accuracy Score:', lg.score(X_test, y_test))

lsvm = SVC()

lsvm.fit(X_train, y_train)

print('Accuracy Score :', lsvm.score(X_test, y_test))

dt=DecisionTreeClassifier()

 dt.fit(X_train,y_train)

 print("Accuracy Score:",dt.score(X_test,y_test))

gnb = GaussianNB()
rf = RandomForestClassifier()
lg = LogisticRegression(max_iter=1000)
lsvm = SVC()
dt = DecisionTreeClassifier()

models = [gnb, rf, lg, lsvm, dt]
model_names = ['GaussianNB', 'RandomForest', 'LogisticRegression', 'SVC', 'DecisionTree']
accuracies = []

for model in models:
    model.fit(X_train, y_train)
    accuracy = model.score(X_test, y_test)
    accuracies.append(accuracy)

plt.figure(figsize=(6,5))
plt.bar(model_names, accuracies, color='skyblue')
plt.xlabel('Classifiers')
plt.ylabel('Accuracy Score')
plt.title('Accuracy Scores of Different Classifiers')
plt.ylim(0, 1)
plt.xticks(rotation=45)
for i, v in enumerate(accuracies):
    plt.text(i, v + 0.01, str(round(v, 3)), ha='center')
plt.show()

y_pred = rf.predict(X_test)

conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)